{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 27\n",
    "intermediate_dim = 12\n",
    "latent_dim = 5\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_sigma = inputs\n",
    "        \n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        \n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        \n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "z = Sampling()([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='tanh')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = keras.losses.MeanSquaredError()\n",
    "reconstruction_loss = mse(inputs, outputs)\n",
    "reconstruction_loss *= 27\n",
    "\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "optimizer=keras.optimizers.Adam()\n",
    "vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Training Samples: 14734\n",
      "No Test Samples: 3684\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/Fs_B_DANCE_WALK_0.5sec.csv')\n",
    "dataset = dataset.drop(columns=['EMOTION_P', 'EMOTION_A', 'EMOTION_D'])\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=42)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(\"No Training Samples:\",train_dataset.shape[0])\n",
    "print(\"No Test Samples:\",test_dataset.shape[0])\n",
    "\n",
    "train_dataset = shuffle(train_dataset)\n",
    "test_dataset = shuffle(test_dataset)\n",
    "\n",
    "train_dataset = np.asarray(train_dataset)\n",
    "test_dataset = np.asarray(test_dataset)\n",
    "\n",
    "x_train = train_dataset.reshape((len(train_dataset), np.prod(train_dataset.shape[1:])))\n",
    "x_test = test_dataset.reshape((len(test_dataset), np.prod(test_dataset.shape[1:])))\n",
    "\n",
    "print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6187\n",
      "Epoch 2/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6232\n",
      "Epoch 3/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6028\n",
      "Epoch 4/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6202\n",
      "Epoch 5/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5948\n",
      "Epoch 6/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6000\n",
      "Epoch 7/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6059\n",
      "Epoch 8/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6126\n",
      "Epoch 9/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6004\n",
      "Epoch 10/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5978\n",
      "Epoch 11/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6027\n",
      "Epoch 12/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6132\n",
      "Epoch 13/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6044\n",
      "Epoch 14/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6009\n",
      "Epoch 15/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6050\n",
      "Epoch 16/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5801\n",
      "Epoch 17/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5939\n",
      "Epoch 18/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5942\n",
      "Epoch 19/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6056\n",
      "Epoch 20/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5905\n",
      "Epoch 21/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6068\n",
      "Epoch 22/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6060\n",
      "Epoch 23/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6006\n",
      "Epoch 24/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5892\n",
      "Epoch 25/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6071\n",
      "Epoch 26/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5999\n",
      "Epoch 27/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5974\n",
      "Epoch 28/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5943\n",
      "Epoch 29/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5989\n",
      "Epoch 30/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5838\n",
      "Epoch 31/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6060\n",
      "Epoch 32/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5957\n",
      "Epoch 33/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5965\n",
      "Epoch 34/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5978\n",
      "Epoch 35/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5830\n",
      "Epoch 36/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5946\n",
      "Epoch 37/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5918\n",
      "Epoch 38/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5920\n",
      "Epoch 39/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5870\n",
      "Epoch 40/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5879\n",
      "Epoch 41/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5943\n",
      "Epoch 42/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6013\n",
      "Epoch 43/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5966\n",
      "Epoch 44/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5979\n",
      "Epoch 45/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5915\n",
      "Epoch 46/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5881\n",
      "Epoch 47/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5933\n",
      "Epoch 48/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5959\n",
      "Epoch 49/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6137\n",
      "Epoch 50/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5872\n",
      "Epoch 51/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5943\n",
      "Epoch 52/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5969\n",
      "Epoch 53/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5949\n",
      "Epoch 54/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5868\n",
      "Epoch 55/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5850\n",
      "Epoch 56/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5975\n",
      "Epoch 57/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5887\n",
      "Epoch 58/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5940\n",
      "Epoch 59/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5967\n",
      "Epoch 60/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5959\n",
      "Epoch 61/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5978\n",
      "Epoch 62/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5905\n",
      "Epoch 63/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.5938\n",
      "Epoch 64/64\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 18.6031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70646e6450>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        epochs=64,\n",
    "        batch_size=16,\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29577057  0.1995598   0.16912828  0.52961919  0.4191004   0.42236775\n",
      "   0.29504198  0.29957959  0.286151    0.2699125  -0.19302982 -0.25811558\n",
      "  -0.07891554  0.93960203  0.19899026  0.0865777   0.19354236  0.77026704\n",
      "   0.82223654  0.38248285  1.10377377  0.21948754  1.22960612  1.64132263\n",
      "   1.25433136  2.40144299  0.29973441]]\n"
     ]
    }
   ],
   "source": [
    "sample = np.asarray(x_test[1])\n",
    "sample = sample.reshape(1,-1)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.4489902e-01 -1.7580755e-02 -1.8120952e-01  7.4662268e-05\n",
      "   9.0170878e-01]]\n"
     ]
    }
   ],
   "source": [
    "mean, var, generated = encoder.predict(sample)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.660388    0.38778755  0.37952667  0.52129537  0.4409387   0.43442106\n",
      "   0.34387523  0.34041178  0.2862039   0.27434883 -0.03574353  0.11459128\n",
      "  -0.05878445  0.720847    0.42815375  0.10664046  0.17576106  0.82648754\n",
      "   0.80613637  0.5783576   0.6343103   0.47255474  1.          1.\n",
      "   1.          1.          0.9982845 ]]\n"
     ]
    }
   ],
   "source": [
    "regen = decoder.predict(generated)\n",
    "print(regen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = xgb.XGBRegressor(verbosity=0)\n",
    "model_p.load_model(\"../../emotion_classifier/model_training/models/l2p_dance_model.json\")\n",
    "\n",
    "model_a = xgb.XGBRegressor(verbosity=0)\n",
    "model_a.load_model(\"../../emotion_classifier/model_training/models/l2a_dance_model.json\")\n",
    "\n",
    "model_d = xgb.XGBRegressor(verbosity=0)\n",
    "model_d.load_model(\"../../emotion_classifier/model_training/models/l2d_dance_model.json\")\n",
    "\n",
    "scaler = joblib.load('../../emotion_classifier/model_training/datasets/scalers/standardizers/Fs_B_S_DANCE_WALK_KIN_0.5sec.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: [[ 0.11446296]\n",
      " [-0.12988538]\n",
      " [-0.11219636]]\n",
      "Predicted: [[0.21994561]\n",
      " [0.05928715]\n",
      " [0.2291142 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogosilva/.local/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/diogosilva/.local/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "scaled_sample = scaler.transform(sample)\n",
    "\n",
    "real_coordinates = (\n",
    "    model_p.predict(scaled_sample),\n",
    "    model_a.predict(scaled_sample),\n",
    "    model_d.predict(scaled_sample)\n",
    ")\n",
    "\n",
    "scaled_regen = scaler.transform(regen)\n",
    "\n",
    "generated_coordinates = (\n",
    "    model_p.predict(scaled_regen),\n",
    "    model_a.predict(scaled_regen),\n",
    "    model_d.predict(scaled_regen)\n",
    ")\n",
    "\n",
    "\n",
    "print('Real: %s' % np.asarray(real_coordinates))\n",
    "print('Predicted: %s' % np.asarray(generated_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
