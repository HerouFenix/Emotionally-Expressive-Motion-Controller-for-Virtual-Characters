{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 20\n",
    "intermediate_dim = 10\n",
    "latent_dim = 5\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_sigma = inputs\n",
    "        \n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        \n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        \n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "z = Sampling()([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='relu')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = keras.losses.MeanSquaredError()\n",
    "reconstruction_loss = mse(inputs, outputs)\n",
    "reconstruction_loss *= 27\n",
    "\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "optimizer=keras.optimizers.Adam()\n",
    "vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Training Samples: 39539\n",
      "No Test Samples: 9885\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/Fs2_B_DANCE_WALK_KIN_0.5sec.csv')\n",
    "dataset = dataset.drop(columns=['EMOTION_P', 'EMOTION_A', 'EMOTION_D'])\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=42)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(\"No Training Samples:\",train_dataset.shape[0])\n",
    "print(\"No Test Samples:\",test_dataset.shape[0])\n",
    "\n",
    "train_dataset = shuffle(train_dataset)\n",
    "test_dataset = shuffle(test_dataset)\n",
    "\n",
    "train_dataset = np.asarray(train_dataset)\n",
    "test_dataset = np.asarray(test_dataset)\n",
    "\n",
    "x_train = train_dataset.reshape((len(train_dataset), np.prod(train_dataset.shape[1:])))\n",
    "x_test = test_dataset.reshape((len(test_dataset), np.prod(test_dataset.shape[1:])))\n",
    "\n",
    "print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 2.5685\n",
      "Epoch 2/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.9825\n",
      "Epoch 3/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.9061\n",
      "Epoch 4/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8728\n",
      "Epoch 5/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8678\n",
      "Epoch 6/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8703\n",
      "Epoch 7/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8554\n",
      "Epoch 8/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8545\n",
      "Epoch 9/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8564\n",
      "Epoch 10/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8544\n",
      "Epoch 11/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8491\n",
      "Epoch 12/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8508\n",
      "Epoch 13/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8484\n",
      "Epoch 14/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8470\n",
      "Epoch 15/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8474\n",
      "Epoch 16/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8459\n",
      "Epoch 17/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8511\n",
      "Epoch 18/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8570\n",
      "Epoch 19/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8398\n",
      "Epoch 20/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8492\n",
      "Epoch 21/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8499\n",
      "Epoch 22/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8428\n",
      "Epoch 23/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8432\n",
      "Epoch 24/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8462\n",
      "Epoch 25/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8472\n",
      "Epoch 26/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8470\n",
      "Epoch 27/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8426\n",
      "Epoch 28/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8403\n",
      "Epoch 29/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8407\n",
      "Epoch 30/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8397\n",
      "Epoch 31/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8454\n",
      "Epoch 32/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8441\n",
      "Epoch 33/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8433\n",
      "Epoch 34/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8375\n",
      "Epoch 35/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8378\n",
      "Epoch 36/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8348\n",
      "Epoch 37/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8374\n",
      "Epoch 38/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8439\n",
      "Epoch 39/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8410\n",
      "Epoch 40/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8387\n",
      "Epoch 41/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8386\n",
      "Epoch 42/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8379\n",
      "Epoch 43/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8441\n",
      "Epoch 44/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8438\n",
      "Epoch 45/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8421\n",
      "Epoch 46/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8398\n",
      "Epoch 47/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8395\n",
      "Epoch 48/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8443\n",
      "Epoch 49/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8421\n",
      "Epoch 50/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8373\n",
      "Epoch 51/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8391\n",
      "Epoch 52/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8342\n",
      "Epoch 53/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8437\n",
      "Epoch 54/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8396\n",
      "Epoch 55/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8406\n",
      "Epoch 56/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8476\n",
      "Epoch 57/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8385\n",
      "Epoch 58/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8396\n",
      "Epoch 59/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8407\n",
      "Epoch 60/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8394\n",
      "Epoch 61/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8377\n",
      "Epoch 62/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8404\n",
      "Epoch 63/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8396\n",
      "Epoch 64/64\n",
      "2472/2472 [==============================] - 3s 1ms/step - loss: 1.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71040cce90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        epochs=64,\n",
    "        batch_size=16,\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5465021   0.28525563  0.29986547  0.34619037  0.47699654  0.48712536\n",
      "   0.36132266  0.36431942  0.286151    0.27884018  0.01677658 -0.09337226\n",
      "  -0.01787424  0.9953223   0.17039936  0.0491959   0.05094272  0.03477383\n",
      "   0.04732112  0.04935516]]\n"
     ]
    }
   ],
   "source": [
    "sample = np.asarray(x_test[1])\n",
    "sample = sample.reshape(1,-1)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12025566 -0.15046847  2.3712182  -0.09588134  2.7085776 ]]\n"
     ]
    }
   ],
   "source": [
    "mean, var, generated = encoder.predict(sample)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5801557  0.36057067 0.37284973 0.40733883 0.41734475 0.42018545\n",
      "  0.3314078  0.33405918 0.28614908 0.2770082  0.         0.\n",
      "  0.         0.87949204 0.33764157 0.5756676  0.5758006  0.37357187\n",
      "  0.39133757 0.38418823]]\n"
     ]
    }
   ],
   "source": [
    "regen = decoder.predict(generated)\n",
    "print(regen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = xgb.XGBRegressor(verbosity=0)\n",
    "model_p.load_model(\"../../emotion_classifier/model_training/models/l2p_dance_model.json\")\n",
    "\n",
    "model_a = xgb.XGBRegressor(verbosity=0)\n",
    "model_a.load_model(\"../../emotion_classifier/model_training/models/l2a_dance_model.json\")\n",
    "\n",
    "model_d = xgb.XGBRegressor(verbosity=0)\n",
    "model_d.load_model(\"../../emotion_classifier/model_training/models/l2d_dance_model.json\")\n",
    "\n",
    "scaler = joblib.load('../../emotion_classifier/model_training/datasets/scalers/standardizers/Fs_B_S_DANCE_WALK_KIN_0.5sec.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: [[ 0.11446296]\n",
      " [-0.12988538]\n",
      " [-0.11219636]]\n",
      "Predicted: [[0.21994561]\n",
      " [0.05928715]\n",
      " [0.2291142 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogosilva/.local/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/diogosilva/.local/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "scaled_sample = scaler.transform(sample)\n",
    "\n",
    "real_coordinates = (\n",
    "    model_p.predict(scaled_sample),\n",
    "    model_a.predict(scaled_sample),\n",
    "    model_d.predict(scaled_sample)\n",
    ")\n",
    "\n",
    "scaled_regen = scaler.transform(regen)\n",
    "\n",
    "generated_coordinates = (\n",
    "    model_p.predict(scaled_regen),\n",
    "    model_a.predict(scaled_regen),\n",
    "    model_d.predict(scaled_regen)\n",
    ")\n",
    "\n",
    "\n",
    "print('Real: %s' % np.asarray(real_coordinates))\n",
    "print('Predicted: %s' % np.asarray(generated_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
