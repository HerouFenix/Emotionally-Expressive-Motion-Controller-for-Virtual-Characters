{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRegression (P,A,D coordinates to LMA Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing the identified emotions of each LMA feature set rather than the normal ones\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current best:\n",
    "#datasets/pad/Fs_B_S_DANCE_WALK_0.5sec.csv\n",
    "\"\"\"\n",
    "Using the identified emotions of each LMA feature set rather than the normal ones\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = xgb.XGBRegressor(verbosity=0)\n",
    "model_p.load_model(\"../../emotion_classifier/model_training/models/l2p_dance_model_O.json\")\n",
    "\n",
    "model_a = xgb.XGBRegressor(verbosity=0)\n",
    "model_a.load_model(\"../../emotion_classifier/model_training/models/l2a_dance_model_O.json\")\n",
    "\n",
    "model_d = xgb.XGBRegressor(verbosity=0)\n",
    "model_d.load_model(\"../../emotion_classifier/model_training/models/l2d_dance_model_O.json\")\n",
    "\n",
    "scaler = joblib.load('../../emotion_classifier/model_training/datasets/scalers/standardizers/Fs_B_O_S_DANCE_WALK_KIN_0.5sec.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('datasets/Fs_B_O_DANCE_WALK_KIN_0.5sec.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.9, random_state=42)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(\"No Training Samples:\",train_dataset.shape[0])\n",
    "print(\"No Test Samples:\",test_dataset.shape[0])\n",
    "\n",
    "train_dataset = shuffle(train_dataset)\n",
    "test_dataset = shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Features from Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emotions = pd.concat([train_dataset.pop(x) for x in ['EMOTION_P', 'EMOTION_A', 'EMOTION_D']], axis=1)\n",
    "train_emotions_OG = train_emotions.copy()\n",
    "\n",
    "test_emotions = pd.concat([test_dataset.pop(x) for x in ['EMOTION_P', 'EMOTION_A', 'EMOTION_D']], axis=1)\n",
    "test_emotions_OG = test_emotions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_scaled = scaler.transform(train_dataset)\n",
    "test_dataset_scaled = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emotions_p = model_p.predict(train_dataset_scaled)\n",
    "train_emotions_a = model_a.predict(train_dataset_scaled)\n",
    "train_emotions_d = model_d.predict(train_dataset_scaled)\n",
    "\n",
    "for i in range(len(train_dataset_scaled)):\n",
    "    train_emotions.iloc[i] = [train_emotions_p[i], train_emotions_a[i], train_emotions_d[i]]\n",
    "\n",
    "train_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emotions_OG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emotions_p = model_p.predict(test_dataset_scaled)\n",
    "test_emotions_a = model_a.predict(test_dataset_scaled)\n",
    "test_emotions_d = model_d.predict(test_dataset_scaled)\n",
    "\n",
    "for i in range(len(test_dataset_scaled)):\n",
    "    test_emotions.iloc[i] = [test_emotions_p[i], test_emotions_a[i], test_emotions_d[i]]\n",
    "\n",
    "\n",
    "test_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emotions_OG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sets = []\n",
    "test_y_sets = []\n",
    "# List of np.arrays each containing the LMA features of a given column (i.e one list per feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in train_dataset.columns:\n",
    "    train_y_sets.append(pd.concat([train_dataset.pop(x) for x in [colname]], axis=1))\n",
    "    \n",
    "for colname in test_dataset.columns:\n",
    "    test_y_sets.append(pd.concat([test_dataset.pop(x) for x in [colname]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_y_sets)):\n",
    "    print(train_y_sets[i].columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = xgb.XGBRegressor(verbosity=1) \n",
    "\n",
    "params = {\n",
    "        'eta': [0.01, 0.05, 0.1],\n",
    "        'min_child_weight': [1, 5, 11, 21],\n",
    "        'max_depth': [3, 6, 10, 15],\n",
    "        'gamma': [0, 0.001, 0.01],\n",
    "        'subsample': [0.75, 1],\n",
    "        'colsample_bytree': [0.75, 1],\n",
    "        'lambda': [1, 1.25],\n",
    "        'alpha': [0.0, 0.25]\n",
    "        }\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(len(train_y_sets)):\n",
    "    models.append(\n",
    "        xgb.XGBRegressor(\n",
    "                    n_estimators=1500, learning_rate=0.05, max_depth=6, min_child_weight=11, \n",
    "                    reg_alpha=0.25, reg_lambda=1.25, gamma=0.01,\n",
    "                    subsample=0.75, colsample_bytree=0.75, objective=\"reg:squarederror\",\n",
    "                    tree_method='gpu_hist'\n",
    "                )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    models[i].fit(train_emotions, train_y_sets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    score = models[i].score(train_emotions, train_y_sets[i])\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    print(\"Training score: \", score)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set MAE & MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    pred_y = models[i].predict(test_emotions)\n",
    "    mse = mean_squared_error(test_y_sets[i], pred_y)\n",
    "    mae = mean_absolute_error(test_y_sets[i], pred_y)\n",
    "    print(test_y_sets[i].columns[0])\n",
    "    print(\"MSE: %.2f\" % mse)\n",
    "    print(\"MAE: %.2f\" % mae)\n",
    "    print(\"Example: \", test_y_sets[i].iloc[0][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_features = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    pred_y = models[i].predict(test_emotions)\n",
    "    generated_features.append(pred_y)\n",
    "    \n",
    "    \n",
    "rows = []\n",
    "for i in range(len(generated_features[0])):\n",
    "    row = []\n",
    "    for j in range(len(models)):\n",
    "        row.append(generated_features[j][i])\n",
    "    rows.append(row)\n",
    "    \n",
    "print(len(rows))\n",
    "        \n",
    "generated = pd.DataFrame(rows, columns=[\n",
    "            \"max_hand_distance\",\n",
    "            \"avg_l_hand_hip_distance\",\n",
    "            \"avg_r_hand_hip_distance\",\n",
    "            \"max_stride_length\",\n",
    "            \"avg_l_hand_chest_distance\",\n",
    "            \"avg_r_hand_chest_distance\",\n",
    "            \"avg_l_elbow_hip_distance\",\n",
    "            \"avg_r_elbow_hip_distance\",\n",
    "            \"avg_chest_pelvis_distance\",\n",
    "            \"avg_neck_chest_distance\",\n",
    "            \"avg_neck_rotation_w\", \"avg_neck_rotation_x\", \"avg_neck_rotation_y\", \"avg_neck_rotation_z\",\n",
    "            \"avg_total_body_volume\",\n",
    "            \"avg_triangle_area_hands_neck\",\n",
    "            \"avg_triangle_area_feet_hips\",\n",
    "          \n",
    "            \"l_hand_speed\",\n",
    "            \"r_hand_speed\",\n",
    "            \"l_foot_speed\",\n",
    "            \"r_foot_speed\",\n",
    "            \"neck_speed\",\n",
    "          \n",
    "            \"l_hand_acceleration_magnitude\",\n",
    "            \"r_hand_acceleration_magnitude\",\n",
    "            \"l_foot_acceleration_magnitude\",\n",
    "            \"r_foot_acceleration_magnitude\",\n",
    "            \"neck_acceleration_magnitude\",\n",
    "         ])\n",
    "\n",
    "generated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_scaled = scaler.transform(generated)\n",
    "\n",
    "gen_emotions_p = model_p.predict(generated_scaled)\n",
    "gen_emotions_a = model_a.predict(generated_scaled)\n",
    "gen_emotions_d = model_d.predict(generated_scaled)\n",
    "\n",
    "rows = []\n",
    "for i in range(len(generated_scaled)):\n",
    "    rows.append([gen_emotions_p[i], gen_emotions_a[i], gen_emotions_d[i]])\n",
    "\n",
    "gen_emotions = pd.DataFrame(rows, columns=[\n",
    "            \"EMOTION_P\", \"EMOTION_A\", \"EMOTION_D\"\n",
    "         ])\n",
    "\n",
    "gen_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "mae_errors = mean_absolute_error(test_emotions, gen_emotions, multioutput='raw_values')\n",
    "mse_errors = mean_squared_error(test_emotions, gen_emotions, multioutput='raw_values')\n",
    "\n",
    "features = [\"PLEASURE\", \"AROUSAL\", \"DOMINANCE\"\n",
    "         ]\n",
    "\n",
    "print(\"Overall MAE: \" + str(mean_absolute_error(test_emotions, gen_emotions)))\n",
    "\n",
    "print()\n",
    "for i in range(len(mse_errors)):\n",
    "    print(\"==\" + features[i] + \"==\")\n",
    "    print(\"MSE: %.5f\" % mse_errors[i])\n",
    "    print(\"MAE: %.5f\" % mae_errors[i])\n",
    "    print()\n",
    "    \n",
    "for i in range(30):\n",
    "    row = random.randint(0, len(test_emotions))\n",
    "\n",
    "    print(\"Real: \" + str([test_emotions_OG.iloc[row,0], test_emotions_OG.iloc[row,1], test_emotions_OG.iloc[row,2]]))\n",
    "    print(\"Predicted: \" + str([test_emotions.iloc[row,0], test_emotions.iloc[row,1], test_emotions.iloc[row,2]]))\n",
    "    print(\"Generated: \" + str([gen_emotions.iloc[row,0], gen_emotions.iloc[row,1], gen_emotions.iloc[row,2]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = xgb.XGBRegressor(verbosity=0)\n",
    "model_p.load_model(\"../../emotion_classifier/model_training/models/l2p_dance_model_O.json\")\n",
    "\n",
    "model_a = xgb.XGBRegressor(verbosity=0)\n",
    "model_a.load_model(\"../../emotion_classifier/model_training/models/l2a_dance_model_O.json\")\n",
    "\n",
    "model_d = xgb.XGBRegressor(verbosity=0)\n",
    "model_d.load_model(\"../../emotion_classifier/model_training/models/l2d_dance_model_O.json\")\n",
    "\n",
    "scaler = joblib.load('../../emotion_classifier/model_training/datasets/scalers/standardizers/Fs_B_O_S_DANCE_WALK_KIN_0.5sec.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 4\n",
    "\n",
    "real_coordinates = np.asarray([test_X.iloc[index]])\n",
    "\n",
    "generated_features = []\n",
    "for i in range(len(models)):\n",
    "    generated_features.append(models[i].predict(real_coordinates)[0])\n",
    "    #print(test_y_sets[i].columns[0], \" - \", generated_features[i])\n",
    "    \n",
    "generated_features = pd.DataFrame([generated_features], columns=[\n",
    "            \"max_hand_distance\",\n",
    "            \"avg_l_hand_hip_distance\",\n",
    "            \"avg_r_hand_hip_distance\",\n",
    "            \"max_stride_length\",\n",
    "            \"avg_l_hand_chest_distance\",\n",
    "            \"avg_r_hand_chest_distance\",\n",
    "            \"avg_l_elbow_hip_distance\",\n",
    "            \"avg_r_elbow_hip_distance\",\n",
    "            \"avg_chest_pelvis_distance\",\n",
    "            \"avg_neck_chest_distance\",\n",
    "            \"avg_neck_rotation_w\", \"avg_neck_rotation_x\", \"avg_neck_rotation_y\", \"avg_neck_rotation_z\",\n",
    "            \"avg_total_body_volume\",\n",
    "            \"avg_triangle_area_hands_neck\",\n",
    "            \"avg_triangle_area_feet_hips\",\n",
    "          \n",
    "            \"l_hand_speed\",\n",
    "            \"r_hand_speed\",\n",
    "            \"l_foot_speed\",\n",
    "            \"r_foot_speed\",\n",
    "            \"neck_speed\",\n",
    "          \n",
    "            \"l_hand_acceleration_magnitude\",\n",
    "            \"r_hand_acceleration_magnitude\",\n",
    "            \"l_foot_acceleration_magnitude\",\n",
    "            \"r_foot_acceleration_magnitude\",\n",
    "            \"neck_acceleration_magnitude\",\n",
    "         ])\n",
    "\n",
    "generated_features = scaler.transform(generated_features)\n",
    "\n",
    "y_p = model_p.predict(generated_features)\n",
    "y_a = model_a.predict(generated_features)\n",
    "y_d = model_d.predict(generated_features)\n",
    "\n",
    "print('Real: %s' % np.asarray(real_coordinates))\n",
    "print('Predicted: %s' % [y_p[0], y_a[0], y_d[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to JSON\n",
    "model_p.save_model(\"models/l2p_dance_model.json\")\n",
    "model_a.save_model(\"models/l2a_dance_model.json\")\n",
    "model_d.save_model(\"models/l2d_dance_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = xgb.XGBRegressor(verbosity=0)\n",
    "model_p.load_model(\"models/l2p_dance_model_v2.json\")\n",
    "\n",
    "model_a = xgb.XGBRegressor(verbosity=0)\n",
    "model_a.load_model(\"models/l2a_dance_model_v2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Grid Search with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb.set_config(verbosity=2)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hand_distance</th>\n",
       "      <th>avg_l_hand_hip_distance</th>\n",
       "      <th>avg_r_hand_hip_distance</th>\n",
       "      <th>max_stride_length</th>\n",
       "      <th>avg_l_hand_chest_distance</th>\n",
       "      <th>avg_r_hand_chest_distance</th>\n",
       "      <th>avg_l_elbow_hip_distance</th>\n",
       "      <th>avg_r_elbow_hip_distance</th>\n",
       "      <th>avg_chest_pelvis_distance</th>\n",
       "      <th>avg_neck_chest_distance</th>\n",
       "      <th>...</th>\n",
       "      <th>r_foot_speed</th>\n",
       "      <th>neck_speed</th>\n",
       "      <th>l_hand_acceleration_magnitude</th>\n",
       "      <th>r_hand_acceleration_magnitude</th>\n",
       "      <th>l_foot_acceleration_magnitude</th>\n",
       "      <th>r_foot_acceleration_magnitude</th>\n",
       "      <th>neck_acceleration_magnitude</th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.684605</td>\n",
       "      <td>0.268051</td>\n",
       "      <td>0.236534</td>\n",
       "      <td>0.478955</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.455152</td>\n",
       "      <td>0.351238</td>\n",
       "      <td>0.336392</td>\n",
       "      <td>0.286151</td>\n",
       "      <td>0.278741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531111</td>\n",
       "      <td>0.677884</td>\n",
       "      <td>1.109843</td>\n",
       "      <td>0.766334</td>\n",
       "      <td>1.537713</td>\n",
       "      <td>1.062221</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438911</td>\n",
       "      <td>0.265254</td>\n",
       "      <td>0.229588</td>\n",
       "      <td>0.283025</td>\n",
       "      <td>0.468163</td>\n",
       "      <td>0.452005</td>\n",
       "      <td>0.350459</td>\n",
       "      <td>0.333469</td>\n",
       "      <td>0.286151</td>\n",
       "      <td>0.278750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.021416</td>\n",
       "      <td>1.085836</td>\n",
       "      <td>0.779991</td>\n",
       "      <td>1.575538</td>\n",
       "      <td>1.049393</td>\n",
       "      <td>1.367237</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.440199</td>\n",
       "      <td>0.266441</td>\n",
       "      <td>0.223630</td>\n",
       "      <td>0.309053</td>\n",
       "      <td>0.455287</td>\n",
       "      <td>0.439872</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>0.325378</td>\n",
       "      <td>0.286151</td>\n",
       "      <td>0.278739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072819</td>\n",
       "      <td>0.191442</td>\n",
       "      <td>1.231576</td>\n",
       "      <td>1.117785</td>\n",
       "      <td>0.133194</td>\n",
       "      <td>0.126177</td>\n",
       "      <td>0.355767</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500120</td>\n",
       "      <td>0.386881</td>\n",
       "      <td>0.393727</td>\n",
       "      <td>0.452718</td>\n",
       "      <td>0.418828</td>\n",
       "      <td>0.440395</td>\n",
       "      <td>0.324313</td>\n",
       "      <td>0.340373</td>\n",
       "      <td>0.286151</td>\n",
       "      <td>0.278729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>0.605356</td>\n",
       "      <td>1.068333</td>\n",
       "      <td>1.038694</td>\n",
       "      <td>1.638293</td>\n",
       "      <td>1.021144</td>\n",
       "      <td>1.332992</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.562528</td>\n",
       "      <td>0.447009</td>\n",
       "      <td>0.596923</td>\n",
       "      <td>0.488571</td>\n",
       "      <td>0.361697</td>\n",
       "      <td>0.522971</td>\n",
       "      <td>0.286162</td>\n",
       "      <td>0.430045</td>\n",
       "      <td>0.286151</td>\n",
       "      <td>0.278747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139125</td>\n",
       "      <td>0.207208</td>\n",
       "      <td>1.304347</td>\n",
       "      <td>1.077684</td>\n",
       "      <td>1.563165</td>\n",
       "      <td>0.917321</td>\n",
       "      <td>0.803440</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_hand_distance  avg_l_hand_hip_distance  avg_r_hand_hip_distance  \\\n",
       "0           0.684605                 0.268051                 0.236534   \n",
       "1           0.438911                 0.265254                 0.229588   \n",
       "2           0.440199                 0.266441                 0.223630   \n",
       "3           0.500120                 0.386881                 0.393727   \n",
       "4           0.562528                 0.447009                 0.596923   \n",
       "\n",
       "   max_stride_length  avg_l_hand_chest_distance  avg_r_hand_chest_distance  \\\n",
       "0           0.478955                   0.469381                   0.455152   \n",
       "1           0.283025                   0.468163                   0.452005   \n",
       "2           0.309053                   0.455287                   0.439872   \n",
       "3           0.452718                   0.418828                   0.440395   \n",
       "4           0.488571                   0.361697                   0.522971   \n",
       "\n",
       "   avg_l_elbow_hip_distance  avg_r_elbow_hip_distance  \\\n",
       "0                  0.351238                  0.336392   \n",
       "1                  0.350459                  0.333469   \n",
       "2                  0.343657                  0.325378   \n",
       "3                  0.324313                  0.340373   \n",
       "4                  0.286162                  0.430045   \n",
       "\n",
       "   avg_chest_pelvis_distance  avg_neck_chest_distance  ...  r_foot_speed  \\\n",
       "0                   0.286151                 0.278741  ...      0.531111   \n",
       "1                   0.286151                 0.278750  ...      0.014436   \n",
       "2                   0.286151                 0.278739  ...      0.072819   \n",
       "3                   0.286151                 0.278729  ...      0.464108   \n",
       "4                   0.286151                 0.278747  ...      0.139125   \n",
       "\n",
       "   neck_speed  l_hand_acceleration_magnitude  r_hand_acceleration_magnitude  \\\n",
       "0    0.677884                       1.109843                       0.766334   \n",
       "1    0.021416                       1.085836                       0.779991   \n",
       "2    0.191442                       1.231576                       1.117785   \n",
       "3    0.605356                       1.068333                       1.038694   \n",
       "4    0.207208                       1.304347                       1.077684   \n",
       "\n",
       "   l_foot_acceleration_magnitude  r_foot_acceleration_magnitude  \\\n",
       "0                       1.537713                       1.062221   \n",
       "1                       1.575538                       1.049393   \n",
       "2                       0.133194                       0.126177   \n",
       "3                       1.638293                       1.021144   \n",
       "4                       1.563165                       0.917321   \n",
       "\n",
       "   neck_acceleration_magnitude  EMOTION_P  EMOTION_A  EMOTION_D  \n",
       "0                     1.355767       -0.5        0.6        0.9  \n",
       "1                     1.367237       -0.5        0.6        0.9  \n",
       "2                     0.355767       -0.5        0.6        0.9  \n",
       "3                     1.332992       -0.5        0.6        0.9  \n",
       "4                     0.803440       -0.5        0.6        0.9  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/Fs_B_O_DANCE_WALK_KIN_0.5sec.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Training Samples: 36166\n",
      "No Test Samples: 4018\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.9, random_state=42)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(\"No Training Samples:\",train_dataset.shape[0])\n",
    "print(\"No Test Samples:\",test_dataset.shape[0])\n",
    "\n",
    "train_dataset = shuffle(train_dataset)\n",
    "test_dataset = shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Features from Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emotions = pd.concat([train_dataset.pop(x) for x in ['EMOTION_P', 'EMOTION_A', 'EMOTION_D']], axis=1)\n",
    "train_emotions_OG = train_emotions.copy()\n",
    "\n",
    "test_emotions = pd.concat([test_dataset.pop(x) for x in ['EMOTION_P', 'EMOTION_A', 'EMOTION_D']], axis=1)\n",
    "test_emotions_OG = test_emotions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_scaled = scaler.transform(train_dataset)\n",
    "test_dataset_scaled = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25101</th>\n",
       "      <td>-0.399437</td>\n",
       "      <td>0.251348</td>\n",
       "      <td>-0.100903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>-0.599208</td>\n",
       "      <td>-0.298902</td>\n",
       "      <td>-0.300571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16970</th>\n",
       "      <td>-0.350736</td>\n",
       "      <td>0.696850</td>\n",
       "      <td>-0.793898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32453</th>\n",
       "      <td>-0.352074</td>\n",
       "      <td>0.701497</td>\n",
       "      <td>-0.800367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28022</th>\n",
       "      <td>0.594213</td>\n",
       "      <td>0.502033</td>\n",
       "      <td>0.202609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMOTION_P  EMOTION_A  EMOTION_D\n",
       "25101  -0.399437   0.251348  -0.100903\n",
       "10803  -0.599208  -0.298902  -0.300571\n",
       "16970  -0.350736   0.696850  -0.793898\n",
       "32453  -0.352074   0.701497  -0.800367\n",
       "28022   0.594213   0.502033   0.202609"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emotions_p = model_p.predict(train_dataset_scaled)\n",
    "train_emotions_a = model_a.predict(train_dataset_scaled)\n",
    "train_emotions_d = model_d.predict(train_dataset_scaled)\n",
    "\n",
    "for i in range(len(train_dataset_scaled)):\n",
    "    train_emotions.iloc[i] = [train_emotions_p[i], train_emotions_a[i], train_emotions_d[i]]\n",
    "\n",
    "train_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25101</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16970</th>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32453</th>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28022</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMOTION_P  EMOTION_A  EMOTION_D\n",
       "25101      -0.40       0.25       -0.1\n",
       "10803      -0.60      -0.30       -0.3\n",
       "16970      -0.35       0.70       -0.8\n",
       "32453      -0.35       0.70       -0.8\n",
       "28022       0.60       0.50        0.2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emotions_OG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.348111</td>\n",
       "      <td>0.696477</td>\n",
       "      <td>-0.777389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17602</th>\n",
       "      <td>-0.599573</td>\n",
       "      <td>-0.300424</td>\n",
       "      <td>-0.294430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>0.094744</td>\n",
       "      <td>0.382892</td>\n",
       "      <td>0.110887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39246</th>\n",
       "      <td>-0.394397</td>\n",
       "      <td>0.258712</td>\n",
       "      <td>-0.101554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37900</th>\n",
       "      <td>0.591561</td>\n",
       "      <td>0.490659</td>\n",
       "      <td>0.200044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMOTION_P  EMOTION_A  EMOTION_D\n",
       "207    -0.348111   0.696477  -0.777389\n",
       "17602  -0.599573  -0.300424  -0.294430\n",
       "27384   0.094744   0.382892   0.110887\n",
       "39246  -0.394397   0.258712  -0.101554\n",
       "37900   0.591561   0.490659   0.200044"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emotions_p = model_p.predict(test_dataset_scaled)\n",
    "test_emotions_a = model_a.predict(test_dataset_scaled)\n",
    "test_emotions_d = model_d.predict(test_dataset_scaled)\n",
    "\n",
    "for i in range(len(test_dataset_scaled)):\n",
    "    test_emotions.iloc[i] = [test_emotions_p[i], test_emotions_a[i], test_emotions_d[i]]\n",
    "\n",
    "\n",
    "test_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17602</th>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39246</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37900</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMOTION_P  EMOTION_A  EMOTION_D\n",
       "207        -0.35       0.70       -0.8\n",
       "17602      -0.60      -0.30       -0.3\n",
       "27384       0.60       0.50        0.2\n",
       "39246      -0.40       0.25       -0.1\n",
       "37900       0.60       0.50        0.2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emotions_OG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_sets = []\n",
    "test_y_sets = []\n",
    "# List of np.arrays each containing the LMA features of a given column (i.e one list per feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in train_dataset.columns:\n",
    "    train_y_sets.append(pd.concat([train_dataset.pop(x) for x in [colname]], axis=1))\n",
    "    \n",
    "for colname in test_dataset.columns:\n",
    "    test_y_sets.append(pd.concat([test_dataset.pop(x) for x in [colname]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25101</th>\n",
       "      <td>-0.399437</td>\n",
       "      <td>0.251348</td>\n",
       "      <td>-0.100903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>-0.599208</td>\n",
       "      <td>-0.298902</td>\n",
       "      <td>-0.300571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16970</th>\n",
       "      <td>-0.350736</td>\n",
       "      <td>0.696850</td>\n",
       "      <td>-0.793898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32453</th>\n",
       "      <td>-0.352074</td>\n",
       "      <td>0.701497</td>\n",
       "      <td>-0.800367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28022</th>\n",
       "      <td>0.594213</td>\n",
       "      <td>0.502033</td>\n",
       "      <td>0.202609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMOTION_P  EMOTION_A  EMOTION_D\n",
       "25101  -0.399437   0.251348  -0.100903\n",
       "10803  -0.599208  -0.298902  -0.300571\n",
       "16970  -0.350736   0.696850  -0.793898\n",
       "32453  -0.352074   0.701497  -0.800367\n",
       "28022   0.594213   0.502033   0.202609"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_hand_distance\n",
      "avg_l_hand_hip_distance\n",
      "avg_r_hand_hip_distance\n",
      "max_stride_length\n",
      "avg_l_hand_chest_distance\n",
      "avg_r_hand_chest_distance\n",
      "avg_l_elbow_hip_distance\n",
      "avg_r_elbow_hip_distance\n",
      "avg_chest_pelvis_distance\n",
      "avg_neck_chest_distance\n",
      "avg_neck_rotation_w\n",
      "avg_neck_rotation_x\n",
      "avg_neck_rotation_y\n",
      "avg_neck_rotation_z\n",
      "avg_total_body_volume\n",
      "avg_triangle_area_hands_neck\n",
      "avg_triangle_area_feet_hips\n",
      "l_hand_speed\n",
      "r_hand_speed\n",
      "l_foot_speed\n",
      "r_foot_speed\n",
      "neck_speed\n",
      "l_hand_acceleration_magnitude\n",
      "r_hand_acceleration_magnitude\n",
      "l_foot_acceleration_magnitude\n",
      "r_foot_acceleration_magnitude\n",
      "neck_acceleration_magnitude\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_y_sets)):\n",
    "    print(train_y_sets[i].columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "params = {\n",
    "        'eta': [0.01, 0.05, 0.1, 0.15],\n",
    "        'min_child_weight': [1, 5, 11, 21],\n",
    "        'max_depth': [3, 6, 10, 15],\n",
    "        'gamma': [0, 0.001, 0.01],\n",
    "        'subsample': [0.75, 1],\n",
    "        'colsample_bytree': [0.75, 1],\n",
    "        'lambda': [0.85, 1, 1.25],\n",
    "        'alpha': [0.0, 0.1, 0.25]\n",
    "        }\n",
    "\n",
    "n_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(len(train_y_sets)):\n",
    "    models.append(\n",
    "        xgb.XGBRegressor(\n",
    "                    n_estimators=1500, \n",
    "                    objective=\"reg:squarederror\",\n",
    "                    tree_method='gpu_hist'\n",
    "                )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_hand_distance\n"
     ]
    }
   ],
   "source": [
    "# Pleasure\n",
    "# run randomized search\n",
    "\n",
    "random_searches = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    \n",
    "    kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    random_search = RandomizedSearchCV(models[i], param_distributions=params,\n",
    "                               cv=kfold, scoring='neg_mean_squared_error', n_iter = n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "    random_search.fit(train_emotions, train_y_sets[i])\n",
    "    \n",
    "    random_searches.append(random_search)\n",
    "\n",
    "    print(\"GridSearchCV took %.2f seconds\"\n",
    "          \" parameter settings.\" % ((time.time() - start)))\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,10):\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    \n",
    "    kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    random_search = RandomizedSearchCV(models[i], param_distributions=params,\n",
    "                               cv=kfold, scoring='neg_mean_squared_error', n_iter = n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "    random_search.fit(train_emotions, train_y_sets[i])\n",
    "    \n",
    "    random_searches.append(random_search)\n",
    "\n",
    "    print(\"GridSearchCV took %.2f seconds\"\n",
    "          \" parameter settings.\" % ((time.time() - start)))\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,15):\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    \n",
    "    kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    random_search = RandomizedSearchCV(models[i], param_distributions=params,\n",
    "                               cv=kfold, scoring='neg_mean_squared_error', n_iter = n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "    random_search.fit(train_emotions, train_y_sets[i])\n",
    "    \n",
    "    random_searches.append(random_search)\n",
    "\n",
    "    print(\"GridSearchCV took %.2f seconds\"\n",
    "          \" parameter settings.\" % ((time.time() - start)))\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,20):\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    \n",
    "    kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    random_search = RandomizedSearchCV(models[i], param_distributions=params,\n",
    "                               cv=kfold, scoring='neg_mean_squared_error', n_iter = n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "    random_search.fit(train_emotions, train_y_sets[i])\n",
    "    \n",
    "    random_searches.append(random_search)\n",
    "\n",
    "    print(\"GridSearchCV took %.2f seconds\"\n",
    "          \" parameter settings.\" % ((time.time() - start)))\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20,27):\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    \n",
    "    kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    random_search = RandomizedSearchCV(models[i], param_distributions=params,\n",
    "                               cv=kfold, scoring='neg_mean_squared_error', n_iter = n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "    random_search.fit(train_emotions, train_y_sets[i])\n",
    "    \n",
    "    random_searches.append(random_search)\n",
    "\n",
    "    print(\"GridSearchCV took %.2f seconds\"\n",
    "          \" parameter settings.\" % ((time.time() - start)))\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_regressors = []\n",
    "for i in range(len(random_searches)):\n",
    "    print(train_y_sets[i].columns[0])\n",
    "    best_regressor = random_searches[i].best_estimator_\n",
    "\n",
    "    print(best_regressor.get_params())\n",
    "    best_regressors.append(best_regressor)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(best_regressors)):\n",
    "    pred_y = best_regressors[i].predict(test_emotions)\n",
    "    mse = mean_squared_error(test_y_sets[i], pred_y)\n",
    "    mae = mean_absolute_error(test_y_sets[i], pred_y)\n",
    "    print(test_y_sets[i].columns[0])\n",
    "    print(\"MSE: %.2f\" % mse)\n",
    "    print(\"MAE: %.2f\" % mae)\n",
    "    print(\"Example: \", test_y_sets[i].iloc[0][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_features = []\n",
    "\n",
    "for i in range(len(best_regressors)):\n",
    "    pred_y = best_regressors[i].predict(test_emotions)\n",
    "    generated_features.append(pred_y)\n",
    "    \n",
    "    \n",
    "rows = []\n",
    "for i in range(len(generated_features[0])):\n",
    "    row = []\n",
    "    for j in range(len(best_regressors)):\n",
    "        row.append(generated_features[j][i])\n",
    "    rows.append(row)\n",
    "    \n",
    "print(len(rows))\n",
    "        \n",
    "generated = pd.DataFrame(rows, columns=[\n",
    "            \"max_hand_distance\",\n",
    "            \"avg_l_hand_hip_distance\",\n",
    "            \"avg_r_hand_hip_distance\",\n",
    "            \"max_stride_length\",\n",
    "            \"avg_l_hand_chest_distance\",\n",
    "            \"avg_r_hand_chest_distance\",\n",
    "            \"avg_l_elbow_hip_distance\",\n",
    "            \"avg_r_elbow_hip_distance\",\n",
    "            \"avg_chest_pelvis_distance\",\n",
    "            \"avg_neck_chest_distance\",\n",
    "            \"avg_neck_rotation_w\", \"avg_neck_rotation_x\", \"avg_neck_rotation_y\", \"avg_neck_rotation_z\",\n",
    "            \"avg_total_body_volume\",\n",
    "            \"avg_triangle_area_hands_neck\",\n",
    "            \"avg_triangle_area_feet_hips\",\n",
    "          \n",
    "            \"l_hand_speed\",\n",
    "            \"r_hand_speed\",\n",
    "            \"l_foot_speed\",\n",
    "            \"r_foot_speed\",\n",
    "            \"neck_speed\",\n",
    "          \n",
    "            \"l_hand_acceleration_magnitude\",\n",
    "            \"r_hand_acceleration_magnitude\",\n",
    "            \"l_foot_acceleration_magnitude\",\n",
    "            \"r_foot_acceleration_magnitude\",\n",
    "            \"neck_acceleration_magnitude\",\n",
    "         ])\n",
    "\n",
    "generated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_scaled = scaler.transform(generated)\n",
    "\n",
    "gen_emotions_p = model_p.predict(generated_scaled)\n",
    "gen_emotions_a = model_a.predict(generated_scaled)\n",
    "gen_emotions_d = model_d.predict(generated_scaled)\n",
    "\n",
    "rows = []\n",
    "for i in range(len(generated_scaled)):\n",
    "    rows.append([gen_emotions_p[i], gen_emotions_a[i], gen_emotions_d[i]])\n",
    "\n",
    "gen_emotions = pd.DataFrame(rows, columns=[\n",
    "            \"EMOTION_P\", \"EMOTION_A\", \"EMOTION_D\"\n",
    "         ])\n",
    "\n",
    "gen_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "mae_errors = mean_absolute_error(test_emotions, gen_emotions, multioutput='raw_values')\n",
    "mse_errors = mean_squared_error(test_emotions, gen_emotions, multioutput='raw_values')\n",
    "\n",
    "features = [\"PLEASURE\", \"AROUSAL\", \"DOMINANCE\"\n",
    "         ]\n",
    "\n",
    "print(\"Overall MAE: \" + str(mean_absolute_error(test_emotions, gen_emotions)))\n",
    "\n",
    "print()\n",
    "for i in range(len(mse_errors)):\n",
    "    print(\"==\" + features[i] + \"==\")\n",
    "    print(\"MSE: %.5f\" % mse_errors[i])\n",
    "    print(\"MAE: %.5f\" % mae_errors[i])\n",
    "    print()\n",
    "    \n",
    "for i in range(30):\n",
    "    row = random.randint(0, len(test_emotions))\n",
    "\n",
    "    print(\"Real: \" + str([test_emotions_OG.iloc[row,0], test_emotions_OG.iloc[row,1], test_emotions_OG.iloc[row,2]]))\n",
    "    print(\"Predicted: \" + str([test_emotions.iloc[row,0], test_emotions.iloc[row,1], test_emotions.iloc[row,2]]))\n",
    "    print(\"Generated: \" + str([gen_emotions.iloc[row,0], gen_emotions.iloc[row,1], gen_emotions.iloc[row,2]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to JSON\n",
    "for i in range(len(best_regressors)):\n",
    "    best_regressors[i].save_model(\"models/0.5_sec/xgb/\" + test_y_sets[i].columns[0] +\"_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = xgb.XGBRegressor(verbosity=0)\n",
    "model_p.load_model(\"../../emotion_classifier/model_training/models/l2p_dance_model.json\")\n",
    "\n",
    "model_a = xgb.XGBRegressor(verbosity=0)\n",
    "model_a.load_model(\"../../emotion_classifier/model_training/models/l2a_dance_model.json\")\n",
    "\n",
    "model_d = xgb.XGBRegressor(verbosity=0)\n",
    "model_d.load_model(\"../../emotion_classifier/model_training/models/l2d_dance_model.json\")\n",
    "\n",
    "scaler = joblib.load('../../emotion_classifier/model_training/datasets/scalers/standardizers/Fs_B_S_DANCE_WALK_KIN_0.5sec.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "\n",
    "real_coordinates = np.asarray([test_X.iloc[index]])\n",
    "\n",
    "generated_features = []\n",
    "for i in range(len(models)):\n",
    "    generated_features.append(best_regressors[i].predict(real_coordinates)[0])\n",
    "    #print(test_y_sets[i].columns[0], \" - \", generated_features[i])\n",
    "    \n",
    "generated_features = pd.DataFrame([generated_features], columns=[\n",
    "            \"max_hand_distance\",\n",
    "            \"avg_l_hand_hip_distance\",\n",
    "            \"avg_r_hand_hip_distance\",\n",
    "            \"max_stride_length\",\n",
    "            \"avg_l_hand_chest_distance\",\n",
    "            \"avg_r_hand_chest_distance\",\n",
    "            \"avg_l_elbow_hip_distance\",\n",
    "            \"avg_r_elbow_hip_distance\",\n",
    "            \"avg_chest_pelvis_distance\",\n",
    "            \"avg_neck_chest_distance\",\n",
    "            \"avg_neck_rotation_w\", \"avg_neck_rotation_x\", \"avg_neck_rotation_y\", \"avg_neck_rotation_z\",\n",
    "            \"avg_total_body_volume\",\n",
    "            \"avg_triangle_area_hands_neck\",\n",
    "            \"avg_triangle_area_feet_hips\",\n",
    "          \n",
    "            \"l_hand_speed\",\n",
    "            \"r_hand_speed\",\n",
    "            \"l_foot_speed\",\n",
    "            \"r_foot_speed\",\n",
    "            \"neck_speed\",\n",
    "          \n",
    "            \"l_hand_acceleration_magnitude\",\n",
    "            \"r_hand_acceleration_magnitude\",\n",
    "            \"l_foot_acceleration_magnitude\",\n",
    "            \"r_foot_acceleration_magnitude\",\n",
    "            \"neck_acceleration_magnitude\",\n",
    "         ])\n",
    "\n",
    "generated_features = scaler.transform(generated_features)\n",
    "\n",
    "y_p = model_p.predict(generated_features)\n",
    "y_a = model_a.predict(generated_features)\n",
    "y_d = model_d.predict(generated_features)\n",
    "\n",
    "print('Real: %s' % np.asarray(real_coordinates))\n",
    "print('Predicted: %s' % [y_p[0], y_a[0], y_d[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
