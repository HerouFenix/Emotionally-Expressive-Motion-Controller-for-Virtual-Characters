{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(111)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_length = 1024\n",
    "\n",
    "train_data = torch.randn((train_data_length, 27))\n",
    "\n",
    "train_data[:, 0] = 2 * math.pi * torch.rand(train_data_length)\n",
    "\n",
    "train_data[:, 1] = torch.sin(train_data[:, 0])\n",
    "\n",
    "train_labels = torch.zeros(train_data_length)\n",
    "\n",
    "train_set = [\n",
    "\n",
    "    (train_data[i], train_labels[i]) for i in range(train_data_length)\n",
    "\n",
    "]\n",
    "\n",
    "print(train_set)\n",
    "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Training Samples: 18400\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/Fs_B_DANCE_WALK_0.5sec.csv')\n",
    "dataset = dataset.drop(columns=['EMOTION_P', 'EMOTION_A', 'EMOTION_D'])\n",
    "#train_data = dataset.sample(frac=1, random_state=42)\n",
    "train_data = dataset.iloc[:18400]\n",
    "\n",
    "print(\"No Training Samples:\",train_data.shape[0])\n",
    "\n",
    "train_data_length = train_data.shape[0]\n",
    "\n",
    "train_data = torch.tensor(train_data.values, dtype=torch.float32)\n",
    "\n",
    "train_labels = torch.zeros(train_data_length)\n",
    "\n",
    "train_set = [\n",
    "\n",
    "    (train_data[i],  train_labels[i]) for i in range(train_data_length)\n",
    "\n",
    "]\n",
    "\n",
    "#print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(27, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.model(x)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(5, 12),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(12, 27),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss D.: 0.01353990938514471\n",
      "Epoch: 0 Loss G.: 0.8258992433547974\n",
      "Epoch: 10 Loss D.: 0.14478416740894318\n",
      "Epoch: 10 Loss G.: 0.6103126406669617\n",
      "Epoch: 20 Loss D.: 0.2086859792470932\n",
      "Epoch: 20 Loss G.: 0.6199708580970764\n",
      "Epoch: 30 Loss D.: 0.11921965330839157\n",
      "Epoch: 30 Loss G.: 0.5277076363563538\n",
      "Epoch: 40 Loss D.: 0.08849553763866425\n",
      "Epoch: 40 Loss G.: 0.6822596788406372\n",
      "Epoch: 50 Loss D.: 0.12051056325435638\n",
      "Epoch: 50 Loss G.: 0.6714287996292114\n",
      "Epoch: 60 Loss D.: 0.1403384655714035\n",
      "Epoch: 60 Loss G.: 0.8170068860054016\n",
      "Epoch: 70 Loss D.: 0.1081857979297638\n",
      "Epoch: 70 Loss G.: 0.6716679334640503\n",
      "Epoch: 80 Loss D.: 0.12228119373321533\n",
      "Epoch: 80 Loss G.: 0.6698785424232483\n",
      "Epoch: 90 Loss D.: 0.09698949754238129\n",
      "Epoch: 90 Loss G.: 0.6768026947975159\n",
      "Epoch: 100 Loss D.: 0.08176574856042862\n",
      "Epoch: 100 Loss G.: 0.6604031920433044\n",
      "Epoch: 110 Loss D.: 0.1335138976573944\n",
      "Epoch: 110 Loss G.: 0.6915494203567505\n",
      "Epoch: 120 Loss D.: 0.07217991352081299\n",
      "Epoch: 120 Loss G.: 0.7187076807022095\n",
      "Epoch: 130 Loss D.: 0.11813966929912567\n",
      "Epoch: 130 Loss G.: 0.5508047342300415\n",
      "Epoch: 140 Loss D.: 0.03228041157126427\n",
      "Epoch: 140 Loss G.: 0.760151743888855\n",
      "Epoch: 150 Loss D.: 0.11235788464546204\n",
      "Epoch: 150 Loss G.: 0.7229999303817749\n",
      "Epoch: 160 Loss D.: 0.05360008776187897\n",
      "Epoch: 160 Loss G.: 0.750588595867157\n",
      "Epoch: 170 Loss D.: 0.10091622173786163\n",
      "Epoch: 170 Loss G.: 0.7082482576370239\n",
      "Epoch: 180 Loss D.: 0.12351998686790466\n",
      "Epoch: 180 Loss G.: 0.7081423401832581\n",
      "Epoch: 190 Loss D.: 0.11493714153766632\n",
      "Epoch: 190 Loss G.: 0.710271954536438\n",
      "Epoch: 200 Loss D.: 0.11335775256156921\n",
      "Epoch: 200 Loss G.: 0.6458645462989807\n",
      "Epoch: 210 Loss D.: 0.06717827171087265\n",
      "Epoch: 210 Loss G.: 0.729970395565033\n",
      "Epoch: 220 Loss D.: 0.10507708042860031\n",
      "Epoch: 220 Loss G.: 0.672699511051178\n",
      "Epoch: 230 Loss D.: 0.1701919138431549\n",
      "Epoch: 230 Loss G.: 0.6919776201248169\n",
      "Epoch: 240 Loss D.: 0.06411692500114441\n",
      "Epoch: 240 Loss G.: 0.7847890853881836\n",
      "Epoch: 250 Loss D.: 0.09166059643030167\n",
      "Epoch: 250 Loss G.: 0.7253790497779846\n",
      "Epoch: 260 Loss D.: 0.09888733923435211\n",
      "Epoch: 260 Loss G.: 0.629169762134552\n",
      "Epoch: 270 Loss D.: 0.0797380656003952\n",
      "Epoch: 270 Loss G.: 0.6466960310935974\n",
      "Epoch: 280 Loss D.: 0.14073936641216278\n",
      "Epoch: 280 Loss G.: 0.6634835004806519\n",
      "Epoch: 290 Loss D.: 0.09432502090930939\n",
      "Epoch: 290 Loss G.: 0.7994584441184998\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for n, (real_samples, _) in enumerate(train_loader):\n",
    "\n",
    "        # Data for training the discriminator\n",
    "\n",
    "        real_samples_labels = torch.ones((batch_size, 1))\n",
    "\n",
    "        latent_space_samples = torch.randn((batch_size, 5))\n",
    "\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "\n",
    "        generated_samples_labels = torch.zeros((batch_size, 1))\n",
    "\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "\n",
    "        all_samples_labels = torch.cat(\n",
    "\n",
    "            (real_samples_labels, generated_samples_labels)\n",
    "\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Training the discriminator\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        output_discriminator = discriminator(all_samples)\n",
    "\n",
    "        loss_discriminator = loss_function(\n",
    "\n",
    "            output_discriminator, all_samples_labels)\n",
    "\n",
    "        loss_discriminator.backward()\n",
    "\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "\n",
    "        # Data for training the generator\n",
    "\n",
    "        latent_space_samples = torch.randn((batch_size, 5))\n",
    "\n",
    "\n",
    "        # Training the generator\n",
    "\n",
    "        generator.zero_grad()\n",
    "\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "\n",
    "        output_discriminator_generated = discriminator(generated_samples)\n",
    "\n",
    "        loss_generator = loss_function(\n",
    "\n",
    "            output_discriminator_generated, real_samples_labels\n",
    "\n",
    "        )\n",
    "\n",
    "        loss_generator.backward()\n",
    "\n",
    "        optimizer_generator.step()\n",
    "\n",
    "\n",
    "        # Show loss\n",
    "\n",
    "        if epoch % 10 == 0 and n == batch_size - 1:\n",
    "\n",
    "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
    "\n",
    "            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_samples = torch.randn(10, 27)\n",
    "generated_samples = generator(latent_space_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7151,  0.3648,  0.3633,  0.6360,  0.4562,  0.2526,  0.3801,  0.3801,\n",
      "         0.3294,  0.3166, -0.0127,  0.0372,  0.2131,  1.0413,  0.4555,  0.0682,\n",
      "         0.1086,  1.4817,  0.4525,  0.4389,  0.6356,  0.3728,  4.8970,  1.1899,\n",
      "         0.1314,  2.8897,  0.9827])\n"
     ]
    }
   ],
   "source": [
    "generated_samples = generated_samples.detach()\n",
    "print(generated_samples[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
