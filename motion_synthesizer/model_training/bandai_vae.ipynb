{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb.set_config(verbosity=0)\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = xgb.XGBRegressor(verbosity=0)\n",
    "model_p.load_model(\"../../emotion_classifier/model_training/models/bandai_l2p_model.json\")\n",
    "\n",
    "model_a = xgb.XGBRegressor(verbosity=0)\n",
    "model_a.load_model(\"../../emotion_classifier/model_training/models/bandai_l2a_model.json\")\n",
    "\n",
    "model_d = xgb.XGBRegressor(verbosity=0)\n",
    "model_d.load_model(\"../../emotion_classifier/model_training/models/bandai_l2d_model.json\")\n",
    "\n",
    "scaler = joblib.load('../../emotion_classifier/model_training/datasets/scalers/standardizers/S_BANDAI_5frame.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hand_distance</th>\n",
       "      <th>avg_l_hand_hip_distance</th>\n",
       "      <th>avg_r_hand_hip_distance</th>\n",
       "      <th>max_stride_length</th>\n",
       "      <th>avg_l_hand_chest_distance</th>\n",
       "      <th>avg_r_hand_chest_distance</th>\n",
       "      <th>avg_l_elbow_hip_distance</th>\n",
       "      <th>avg_r_elbow_hip_distance</th>\n",
       "      <th>avg_chest_pelvis_distance</th>\n",
       "      <th>avg_neck_chest_distance</th>\n",
       "      <th>...</th>\n",
       "      <th>r_foot_speed</th>\n",
       "      <th>neck_speed</th>\n",
       "      <th>l_hand_acceleration_magnitude</th>\n",
       "      <th>r_hand_acceleration_magnitude</th>\n",
       "      <th>l_foot_acceleration_magnitude</th>\n",
       "      <th>r_foot_acceleration_magnitude</th>\n",
       "      <th>neck_acceleration_magnitude</th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433596</td>\n",
       "      <td>0.130036</td>\n",
       "      <td>0.335475</td>\n",
       "      <td>0.538619</td>\n",
       "      <td>0.184473</td>\n",
       "      <td>0.310089</td>\n",
       "      <td>0.210679</td>\n",
       "      <td>0.093915</td>\n",
       "      <td>0.236151</td>\n",
       "      <td>0.223894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137483</td>\n",
       "      <td>-0.139467</td>\n",
       "      <td>0.092920</td>\n",
       "      <td>0.196129</td>\n",
       "      <td>0.221155</td>\n",
       "      <td>0.137483</td>\n",
       "      <td>0.139467</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348051</td>\n",
       "      <td>0.145184</td>\n",
       "      <td>0.256784</td>\n",
       "      <td>0.455501</td>\n",
       "      <td>0.197954</td>\n",
       "      <td>0.284215</td>\n",
       "      <td>0.172405</td>\n",
       "      <td>0.104876</td>\n",
       "      <td>0.236151</td>\n",
       "      <td>0.223894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072441</td>\n",
       "      <td>-0.095084</td>\n",
       "      <td>0.048935</td>\n",
       "      <td>0.032804</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.072096</td>\n",
       "      <td>0.045111</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.320294</td>\n",
       "      <td>0.206306</td>\n",
       "      <td>0.180224</td>\n",
       "      <td>0.380190</td>\n",
       "      <td>0.234406</td>\n",
       "      <td>0.259905</td>\n",
       "      <td>0.133006</td>\n",
       "      <td>0.127385</td>\n",
       "      <td>0.236151</td>\n",
       "      <td>0.223894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039016</td>\n",
       "      <td>-0.093423</td>\n",
       "      <td>0.030819</td>\n",
       "      <td>0.043059</td>\n",
       "      <td>0.028182</td>\n",
       "      <td>0.036532</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400389</td>\n",
       "      <td>0.287300</td>\n",
       "      <td>0.136974</td>\n",
       "      <td>0.319861</td>\n",
       "      <td>0.279208</td>\n",
       "      <td>0.239450</td>\n",
       "      <td>0.112632</td>\n",
       "      <td>0.156856</td>\n",
       "      <td>0.236151</td>\n",
       "      <td>0.223894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036825</td>\n",
       "      <td>-0.101489</td>\n",
       "      <td>0.044534</td>\n",
       "      <td>0.054382</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.012813</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465923</td>\n",
       "      <td>0.356129</td>\n",
       "      <td>0.136171</td>\n",
       "      <td>0.309995</td>\n",
       "      <td>0.313229</td>\n",
       "      <td>0.224432</td>\n",
       "      <td>0.112950</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>0.236151</td>\n",
       "      <td>0.223894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054338</td>\n",
       "      <td>-0.117573</td>\n",
       "      <td>0.044670</td>\n",
       "      <td>0.036618</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.022012</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_hand_distance  avg_l_hand_hip_distance  avg_r_hand_hip_distance  \\\n",
       "0           0.433596                 0.130036                 0.335475   \n",
       "1           0.348051                 0.145184                 0.256784   \n",
       "2           0.320294                 0.206306                 0.180224   \n",
       "3           0.400389                 0.287300                 0.136974   \n",
       "4           0.465923                 0.356129                 0.136171   \n",
       "\n",
       "   max_stride_length  avg_l_hand_chest_distance  avg_r_hand_chest_distance  \\\n",
       "0           0.538619                   0.184473                   0.310089   \n",
       "1           0.455501                   0.197954                   0.284215   \n",
       "2           0.380190                   0.234406                   0.259905   \n",
       "3           0.319861                   0.279208                   0.239450   \n",
       "4           0.309995                   0.313229                   0.224432   \n",
       "\n",
       "   avg_l_elbow_hip_distance  avg_r_elbow_hip_distance  \\\n",
       "0                  0.210679                  0.093915   \n",
       "1                  0.172405                  0.104876   \n",
       "2                  0.133006                  0.127385   \n",
       "3                  0.112632                  0.156856   \n",
       "4                  0.112950                  0.186680   \n",
       "\n",
       "   avg_chest_pelvis_distance  avg_neck_chest_distance  ...  r_foot_speed  \\\n",
       "0                   0.236151                 0.223894  ...     -0.137483   \n",
       "1                   0.236151                 0.223894  ...     -0.072441   \n",
       "2                   0.236151                 0.223894  ...     -0.039016   \n",
       "3                   0.236151                 0.223894  ...     -0.036825   \n",
       "4                   0.236151                 0.223894  ...     -0.054338   \n",
       "\n",
       "   neck_speed  l_hand_acceleration_magnitude  r_hand_acceleration_magnitude  \\\n",
       "0   -0.139467                       0.092920                       0.196129   \n",
       "1   -0.095084                       0.048935                       0.032804   \n",
       "2   -0.093423                       0.030819                       0.043059   \n",
       "3   -0.101489                       0.044534                       0.054382   \n",
       "4   -0.117573                       0.044670                       0.036618   \n",
       "\n",
       "   l_foot_acceleration_magnitude  r_foot_acceleration_magnitude  \\\n",
       "0                       0.221155                       0.137483   \n",
       "1                       0.070625                       0.072096   \n",
       "2                       0.028182                       0.036532   \n",
       "3                       0.015679                       0.012813   \n",
       "4                       0.020074                       0.022012   \n",
       "\n",
       "   neck_acceleration_magnitude  EMOTION_P  EMOTION_A  EMOTION_D  \n",
       "0                     0.139467       0.05       -0.4        0.0  \n",
       "1                     0.045111       0.05       -0.4        0.0  \n",
       "2                     0.014232       0.05       -0.4        0.0  \n",
       "3                     0.021506       0.05       -0.4        0.0  \n",
       "4                     0.024961       0.05       -0.4        0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/BANDAI_5frame.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Training Samples: 74623\n",
      "No Test Samples: 3928\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.95, random_state=42)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(\"No Training Samples:\",train_dataset.shape[0])\n",
    "print(\"No Test Samples:\",test_dataset.shape[0])\n",
    "\n",
    "train_dataset = shuffle(train_dataset)\n",
    "test_dataset = shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emotions = pd.concat([train_dataset.pop(x) for x in ['EMOTION_P', 'EMOTION_A', 'EMOTION_D']], axis=1)\n",
    "train_emotions_OG = train_emotions.copy()\n",
    "\n",
    "test_emotions = pd.concat([test_dataset.pop(x) for x in ['EMOTION_P', 'EMOTION_A', 'EMOTION_D']], axis=1)\n",
    "test_emotions_OG = test_emotions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125231</td>\n",
       "      <td>-0.347150</td>\n",
       "      <td>-0.073132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.204304</td>\n",
       "      <td>-0.067318</td>\n",
       "      <td>0.048539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158746</td>\n",
       "      <td>-0.327179</td>\n",
       "      <td>-0.099823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098928</td>\n",
       "      <td>-0.321751</td>\n",
       "      <td>-0.036743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.173503</td>\n",
       "      <td>-0.123865</td>\n",
       "      <td>-0.068499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMOTION_P  EMOTION_A  EMOTION_D\n",
       "0   0.125231  -0.347150  -0.073132\n",
       "1   0.204304  -0.067318   0.048539\n",
       "2   0.158746  -0.327179  -0.099823\n",
       "3   0.098928  -0.321751  -0.036743\n",
       "4   0.173503  -0.123865  -0.068499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emotions_p = model_p.predict(train_dataset)\n",
    "train_emotions_a = model_a.predict(train_dataset)\n",
    "train_emotions_d = model_d.predict(train_dataset)\n",
    "\n",
    "rows = []\n",
    "for i in range(len(train_dataset)):\n",
    "    rows.append([train_emotions_p[i], train_emotions_a[i], train_emotions_d[i]])\n",
    "\n",
    "train_emotions = pd.DataFrame(rows, columns=[\n",
    "            \"EMOTION_P\", \"EMOTION_A\", \"EMOTION_D\"\n",
    "         ])\n",
    "\n",
    "train_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION_P</th>\n",
       "      <th>EMOTION_A</th>\n",
       "      <th>EMOTION_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112296</td>\n",
       "      <td>-0.353002</td>\n",
       "      <td>-0.039603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161262</td>\n",
       "      <td>-0.240276</td>\n",
       "      <td>-0.053446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156622</td>\n",
       "      <td>-0.209693</td>\n",
       "      <td>-0.012130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124465</td>\n",
       "      <td>-0.365829</td>\n",
       "      <td>-0.083854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168878</td>\n",
       "      <td>-0.243771</td>\n",
       "      <td>-0.059709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMOTION_P  EMOTION_A  EMOTION_D\n",
       "0   0.112296  -0.353002  -0.039603\n",
       "1   0.161262  -0.240276  -0.053446\n",
       "2   0.156622  -0.209693  -0.012130\n",
       "3   0.124465  -0.365829  -0.083854\n",
       "4   0.168878  -0.243771  -0.059709"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emotions_p = model_p.predict(test_dataset)\n",
    "test_emotions_a = model_a.predict(test_dataset)\n",
    "test_emotions_d = model_d.predict(test_dataset)\n",
    "\n",
    "rows = []\n",
    "for i in range(len(test_dataset)):\n",
    "    rows.append([test_emotions_p[i], test_emotions_a[i], test_emotions_d[i]])\n",
    "\n",
    "test_emotions = pd.DataFrame(rows, columns=[\n",
    "            \"EMOTION_P\", \"EMOTION_A\", \"EMOTION_D\"\n",
    "         ])\n",
    "\n",
    "test_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(input_vols, output_vols):\n",
    "    beta = 1e-7\n",
    "    kl_loss = K.sum(-1 - K.log(K.exp(log_var)) + K.exp(log_var) + K.square(mu))/2\n",
    "    return K.mean((input_vols-output_vols)**2) + beta*kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 15)           390         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 10)           160         ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 5)            55          ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 5)            30          ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 5)            30          ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_2 (Sampling)          (None, 5)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 5\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(25, ))\n",
    "x = layers.Dense(15, activation=\"relu\")(encoder_inputs)\n",
    "x = layers.Dense(10, activation=\"relu\")(x)\n",
    "x = layers.Dense(5, activation=\"relu\")(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                60        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 15)                165       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                320       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 25)                525       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,070\n",
      "Trainable params: 1,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(10, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(15, activation=\"relu\")(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "\n",
    "decoder_outputs = layers.Dense((25, )[0], activation=\"linear\")(x)\n",
    "\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        \n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            \n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = keras.losses.mean_squared_error(data, reconstruction)\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            \n",
    "            total_loss = (100 * reconstruction_loss) + (kl_loss)\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2332/2332 [==============================] - 4s 1ms/step - loss: 1.6972 - reconstruction_loss: 0.0096 - kl_loss: 0.0041\n",
      "Epoch 2/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7513 - reconstruction_loss: 0.0075 - kl_loss: 7.2889e-06\n",
      "Epoch 3/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7450 - reconstruction_loss: 0.0075 - kl_loss: 4.0257e-06\n",
      "Epoch 4/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7451 - reconstruction_loss: 0.0075 - kl_loss: 3.8303e-06\n",
      "Epoch 5/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7478 - reconstruction_loss: 0.0075 - kl_loss: 3.8174e-06\n",
      "Epoch 6/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7459 - reconstruction_loss: 0.0075 - kl_loss: 1.8254e-06\n",
      "Epoch 7/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7462 - reconstruction_loss: 0.0075 - kl_loss: 1.1270e-06\n",
      "Epoch 8/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7449 - reconstruction_loss: 0.0075 - kl_loss: 8.9110e-07\n",
      "Epoch 9/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7487 - reconstruction_loss: 0.0075 - kl_loss: 2.3873e-08\n",
      "Epoch 10/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7491 - reconstruction_loss: 0.0075 - kl_loss: 9.1843e-07\n",
      "Epoch 11/64\n",
      "2332/2332 [==============================] - 3s 1ms/step - loss: 0.7468 - reconstruction_loss: 0.0075 - kl_loss: 8.0653e-08\n",
      "Epoch 12/64\n",
      "  75/2332 [..............................] - ETA: 3s - loss: 0.7531 - reconstruction_loss: 0.0075 - kl_loss: 8.3844e-08"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8fab578cbf33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3243\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3244\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3246\u001b[0m       \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m       \u001b[0mflat_inputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   2794\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m     if isinstance(value,\n\u001b[0;32m-> 2796\u001b[0;31m                   (ops.Tensor, resource_variable_ops.BaseResourceVariable)):\n\u001b[0m\u001b[1;32m   2797\u001b[0m       \u001b[0mfiltered_flat_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m     elif hasattr(value, \"__array__\") and not (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(train_dataset, epochs=64, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dict = {\n",
    "    (0.05, -0.4, 0.0): \"neutral\",\n",
    "    (0.15, -0.7, -0.2): \"tired\",\n",
    "    (-0.1, -0.55, -0.15): \"exhausted\",\n",
    "    (0.2, -0.75, -0.3): \"exhausted_2\",\n",
    "    (-0.5, 0.8, 0.9): \"angry\",\n",
    "    (0.8, 0.5, 0.15): \"happy\",\n",
    "    (0.6, 0.4, 0.1): \"happy_2\",\n",
    "    (-0.6, -0.4, -0.3): \"sad\",\n",
    "    (0.4, 0.2, 0.3): \"proud\", \n",
    "    (0.3, 0.3, 0.9): \"confident\", \n",
    "    (0.25, 0.15, 0.3): \"confident_2\",\n",
    "    (0.25, 0.15, 0.3): \"confident_3\",\n",
    "    (0.3, 0.4, 0.6): \"confident_4\", \n",
    "    (-0.6, 0.7, -0.8): \"afraid\",\n",
    "    (0.1, 0.6, 0.4): \"active\", \n",
    "}\n",
    "\n",
    "colour_dict = {\n",
    "    \"neutral\": \"crimson\",\n",
    "    \"tired\": \"springgreen\",\n",
    "    \"exhausted\": \"cornflowerblue\",\n",
    "    \"exhausted_2\": \"darkorange\"  ,\n",
    "    \"angry\": \"gold\",\n",
    "    \"happy\": \"olive\",\n",
    "    \"happy_2\": \"lightseagreen\",\n",
    "    \"sad\": \"plum\",\n",
    "    \"proud\": \"chocolate\",\n",
    "    \"confident\": \"olivedrab\",\n",
    "    \"confident_2\": \"purple\",\n",
    "    \"confident_4\": \"lightslategray\",\n",
    "    \"afraid\": \"lightpink\", \n",
    "    \"active\": \"slateblue\", \n",
    "}\n",
    "\n",
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    actual_labels = []\n",
    "    for i in range(len(labels)):\n",
    "        point_coords = (labels.iloc[i][0], labels.iloc[i][1], labels.iloc[i][2])\n",
    "\n",
    "        actual_labels.append(colour_dict[conv_dict[point_coords]])\n",
    "\n",
    "    \n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=actual_labels)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "plot_label_clusters(vae, test_dataset, test_emotions_OG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6066639   0.25030951  0.36207177  0.44697082  0.30988349  0.34038932\n",
      "   0.18311099  0.1162812   0.23615099  0.22389402  0.26641542  0.09919871\n",
      "   0.06424907  0.10578747  0.16329062 -0.10280018 -0.06087656 -0.0186052\n",
      "  -0.08945924 -0.07371857  0.01320025  0.02030674  0.01414669  0.01907025\n",
      "   0.01265828]]\n"
     ]
    }
   ],
   "source": [
    "sample = np.asarray(test_dataset.iloc[1])\n",
    "sample = sample.reshape(1,-1)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0225942   0.29392263  0.07719255  1.0344585  -1.0845417 ]]\n"
     ]
    }
   ],
   "source": [
    "mean, var, generated = encoder.predict(sample)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5506572   0.32379323  0.31053263  0.4553539   0.34142768  0.34105572\n",
      "   0.23057324  0.22952063  0.23614955  0.22389574  0.345175    0.08628955\n",
      "   0.08113877  0.09854872  0.14678863 -0.09339849 -0.09299247 -0.09039417\n",
      "  -0.08972329 -0.08726535  0.01823894  0.01915274  0.02006095  0.01667385\n",
      "   0.01130016]]\n"
     ]
    }
   ],
   "source": [
    "regen = decoder.predict(generated)\n",
    "print(regen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: [[0.6026331 ]\n",
      " [0.42717165]\n",
      " [0.11683352]]\n",
      "Predicted: [[ 0.1870146 ]\n",
      " [-0.3148598 ]\n",
      " [-0.14555968]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogosilva/.local/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/diogosilva/.local/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "scaled_sample = scaler.transform(sample)\n",
    "\n",
    "real_coordinates = (\n",
    "    model_p.predict(scaled_sample),\n",
    "    model_a.predict(scaled_sample),\n",
    "    model_d.predict(scaled_sample)\n",
    ")\n",
    "\n",
    "scaled_regen = scaler.transform(regen)\n",
    "\n",
    "generated_coordinates = (\n",
    "    model_p.predict(scaled_regen),\n",
    "    model_a.predict(scaled_regen),\n",
    "    model_d.predict(scaled_regen)\n",
    ")\n",
    "\n",
    "\n",
    "print('Real: %s' % np.asarray(real_coordinates))\n",
    "print('Predicted: %s' % np.asarray(generated_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
